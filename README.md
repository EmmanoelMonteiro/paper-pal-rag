# üìö Paper-Pal-RAG: Assistente de Leitura para Artigos Cient√≠ficos

---

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.9+-blue?style=for-the-badge&logo=python" alt="Python Version">
  <img src="https://img.shields.io/badge/LangChain-v0.2+-success?style=for-the-badge&logo=langchain" alt="LangChain Version">
  <img src="https://img.shields.io/badge/LM_Studio-Compatible-informational?style=for-the-badge&logo=ai" alt="LM Studio Compatible">
  <img src="https://img.shields.io/badge/ChromaDB-Local-important?style=for-the-badge" alt="ChromaDB">
</p>

## Vis√£o Geral do Projeto

O **Paper-Pal-RAG** √© um assistente de leitura inteligente em **Python** que usa **Retrieval Augmented Generation (RAG)** para ajudar voc√™ a extrair e entender informa√ß√µes de artigos cient√≠ficos.

Este projeto mostra uma arquitetura modular e escal√°vel, usando **LangChain** para orquestra√ß√£o, **LM Studio** como servidor da Large Language Model (LLM) local, e **ChromaDB** para armazenamento vetorial. √â perfeito para quem busca uma solu√ß√£o robusta e com arquitetura limpa para processar e consultar documentos.

## ‚ú® Funcionalidades

* **Ingest√£o de Documentos Flex√≠vel**: Carrega artigos cient√≠ficos em **PDF** (`PyPDFLoader`) e **TXT** (`TextLoader`).
* **Gera√ß√£o Aumentada por Recupera√ß√£o (RAG)**: O sistema busca informa√ß√µes relevantes nos seus documentos antes de gerar uma resposta com a LLM.
* **LLM Local com LM Studio**: Conecta-se facilmente a uma LLM rodando localmente via [LM Studio](https://lmstudio.ai/), garantindo privacidade e controle.
* **Armazenamento Vetorial Persistente**: Usa **ChromaDB** para armazenar e consultar embeddings de documentos de forma eficiente e persistente.
* **Interface de Chat Simples**: Interaja com o assistente por linha de comando, fazendo perguntas sobre o conte√∫do dos artigos.
* **Contexto Transparente**: Al√©m da resposta da LLM, o sistema mostra o **ID do chunk** e o **conte√∫do exato dos documentos** usados como base para a resposta, o que ajuda na valida√ß√£o e depura√ß√£o.
* **Arquitetura Limpa**: O c√≥digo √© organizado em camadas (`core`, `data`, `domain`, `infrastructure`, `presentation`) para promover modularidade, testabilidade e facilitar futuras expans√µes.

## üöÄ Como Executar o Projeto

Siga os passos abaixo para configurar e rodar o Paper-Pal-RAG no seu ambiente local.

### Pr√©-requisitos

* **Python 3.9+**: Verifique sua vers√£o com `python --version`.
* **LM Studio**: Baixe e instale o [LM Studio](https://lmstudio.ai/).

### 1. Clonar o Reposit√≥rio

```bash
git clone [https://github.com/seu-usuario/Paper-Pal-RAG.git](https://github.com/seu-usuario/Paper-Pal-RAG.git)
cd Paper-Pal-RAG
```

### 2. Configurar o Ambiente Virtual

√â **altamente recomendado** usar um ambiente virtual para gerenciar as depend√™ncias do projeto.

```bash
python -m venv .venv
```

### 3. Ativar o Ambiente Virtual
* Windows (PowerShell):

```bash
.\.venv\Scripts\activate
```

* Linux / macOS (Bash/Zsh):
```bash
source ./.venv/bin/activate
```

### 4. Instalar Depend√™ncias
Crie um arquivo chamado requirements.txt na raiz do projeto com o seguinte conte√∫do:

```bash
langchain
langchain-community
langchain-openai
pypdf
chromadb
python-dotenv
sentence-transformers
```
Agora, instale as depend√™ncias:

```bash
pip install -r requirements.txt
```

### 5. Configurar o LM Studio
1. Abra o LM Studio.

2. Na barra lateral esquerda, navegue at√© a se√ß√£o **"Home"** (√≠cone de casa) ou **"Discover"** (√≠cone de lupa) para encontrar e baixar um modelo de sua prefer√™ncia (ex: `gemma-2b-it` ou um modelo da s√©rie Llama).

3. V√° para a aba **"Local Inference Server"** (geralmente a quarta aba, √≠cone de terminal com "localhost").

4. Clique em **"Start Server"**. Certifique-se de que o servidor est√° rodando na porta `1234` (esta √© a porta padr√£o e configurada no projeto).

### 6. Configurar Vari√°veis de Ambiente
Crie um arquivo chamado .env na raiz do seu projeto (Paper-Pal-RAG/) e adicione as seguintes linhas:

```bash
# .env
LM_STUDIO_API_BASE=http://localhost:1234/v1
LM_STUDIO_MODEL_NAME=lm_studio_default # Ou o nome exato do modelo que voc√™ carregou no LM Studio, ex: gemma-2-2b-it
```

### 7. Adicionar seus Artigos
Crie uma pasta chamada `articles` dentro de `data/` na raiz do seu projeto. Coloque seus arquivos **PDFs** e **TXTs** dentro de `Paper-Pal-RAG/data/articles/.`

### 8. Estrutura do Projeto (Certifique-se de que os __init__.py existem!)
Para que o Python reconhe√ßa a estrutura de m√≥dulos corretamente, verifique se arquivos `__init__.py` (que podem ser vazios) existem nas seguintes pastas:

```bash
Paper-Pal-RAG/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py          <- DEVE EXISTIR
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py      <- DEVE EXISTIR
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py      <- DEVE EXISTIR
‚îÇ   ‚îú‚îÄ‚îÄ domain/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py      <- DEVE EXISTIR
‚îÇ   ‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py      <- DEVE EXISTIR
‚îÇ   ‚îú‚îÄ‚îÄ presentation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py      <- DEVE EXISTIR
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ articles/
‚îÇ       ‚îî‚îÄ‚îÄ seu_artigo.pdf
‚îÇ       ‚îî‚îÄ‚îÄ suas_notas.txt
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```
### 9. Executar o Chatbot
Com o ambiente virtual ativado e o LM Studio rodando, execute o projeto a partir da raiz do seu diret√≥rio:

```bash
python -m src.main
```

## ü§ù Como Usar o Chatbot

Ao iniciar, voc√™ ver√° uma mensagem de boas-vindas. Siga os comandos:

1. **Ingerir Documentos:** Digite `ingest` e pressione Enter. O sistema carregar√° e processar√° todos os artigos na pasta `data/articles/`, criando ou atualizando o banco de dados vetorial (`data/chroma_db`).

```bash
Voc√™ (ou digite um comando): ingest
```

2. **Fazer Perguntas:** Ap√≥s a ingest√£o, digite sua pergunta sobre o conte√∫do dos artigos.

```bash
Voc√™ (ou digite um comando): Qual a metodologia principal do estudo sobre IA?
```

3. **Visualizar Contexto:** A resposta incluir√° a gera√ß√£o da LLM e os trechos exatos dos documentos (com seus IDs e nome de arquivo) que foram usados como contexto para a resposta.

4. **Limpar Documentos:** Para remover todos os documentos do banco de dados, digite `clear`.

```bash
Voc√™ (ou digite um comando): clear
```

5. **Sair:** Digite `exit` ou `quit` para encerrar o chatbot.

Sinta-se √† vontade para explorar, modificar e contribuir para este projeto. Sua colabora√ß√£o √© bem-vinda!

Qualquer d√∫vida ou problema, sinta-se √† vontade para abrir uma issue no reposit√≥rio.